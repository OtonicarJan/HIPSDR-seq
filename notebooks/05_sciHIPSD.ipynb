{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from muon import atac as ac\n",
    "from muon._atac import tools as tools\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(1, \"../helper_functions\")\n",
    "from helper_functions import gini, lorenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_files = glob.glob(\"../../sci/LFS_*/readCount_filtered_bam/*.seg\")\n",
    "len(all_count_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_regex = r\"([ACGT]+-\\d+)[.]\"\n",
    "\n",
    "# Function to process a single file\n",
    "\n",
    "\n",
    "def process_file(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        counts = {}\n",
    "        for line in file:\n",
    "            if line.startswith(\"fixedStep\"):\n",
    "                # Parse the header to update chromosome, start, and step\n",
    "                parts = line.strip().split()\n",
    "                chrom = parts[1].split(\"=\")[1]\n",
    "                start = int(parts[2].split(\"=\")[1])\n",
    "                step = int(parts[3].split(\"=\")[1])\n",
    "            else:\n",
    "                # Process count lines\n",
    "                end = start + step - 1  # Assuming span equals step\n",
    "                coord_key = f\"{chrom}:{start}-{end}\"\n",
    "                counts[coord_key] = int(line.strip())\n",
    "                start += step  # Prepare start for the next segment\n",
    "        return counts\n",
    "\n",
    "\n",
    "# Initialize a DataFrame to collect counts for all files\n",
    "all_counts = []\n",
    "all_barcodes = []\n",
    "# Process each file and collect counts\n",
    "for file_path in tqdm(all_count_files):\n",
    "    file_counts = process_file(file_path)\n",
    "    all_counts.append(file_counts)\n",
    "    match = re.search(barcode_regex, file_path)\n",
    "    barcode_id = match.group(1)\n",
    "    idx = \"_\".join(file_path.split(\"/\")[-3].split(\"-\")[:2])\n",
    "    barcode_id = idx + \"_\" + barcode_id\n",
    "    all_barcodes.append(barcode_id)\n",
    "\n",
    "count_matrix = pd.DataFrame(all_counts)\n",
    "count_matrix.index = all_barcodes\n",
    "count_matrix\n",
    "count_matrix.to_csv(\"../data/sciHIPSD_raw_counts.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = pd.read_csv(\"../data/sciHIPSD_raw_counts.csv.gz\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_matac = count_matrix.apply(lambda row: gini(row), axis=1).values\n",
    "lorenz_matac = count_matrix.apply(lambda row: lorenz(row), axis=1).values\n",
    "lorenz_matac_2d = np.array([np.array(x) for x in lorenz_matac])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_lorenz = np.nanmedian(lorenz_matac_2d, axis=0)\n",
    "# Calculate the 95% confidence interval for each point\n",
    "lower_bound = np.nanpercentile(lorenz_matac_2d, 2.5, axis=0)\n",
    "upper_bound = np.nanpercentile(lorenz_matac_2d, 97.5, axis=0)\n",
    "\n",
    "# X-axis values - normalized to range from 0 to 1\n",
    "x_values = np.arange(len(median_lorenz)) / (len(median_lorenz) - 1)\n",
    "\n",
    "# Plotting the median Lorenz curve\n",
    "plt.plot(x_values, median_lorenz, label=\"Median Lorenz Curve\", lw=2, color=\"blue\")\n",
    "plt.plot(x_values, x_values, label=\"uniform\", ls=\"--\", color=\"grey\")\n",
    "\n",
    "\n",
    "# Shading the area representing the confidence interval\n",
    "plt.fill_between(\n",
    "    x_values,\n",
    "    lower_bound,\n",
    "    upper_bound,\n",
    "    color=\"lightblue\",\n",
    "    alpha=0.5,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Additional plot formatting\n",
    "plt.xlabel(\"Fraction of genome\")\n",
    "plt.ylabel(\"Cumulative Share of reads\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gini_matac, count_matrix.sum(axis=1))\n",
    "plt.xlabel(\"Gini\")\n",
    "plt.ylabel(\"Total counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atac = ad.AnnData(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(atac, percent_top=None, log1p=False, inplace=True)\n",
    "atac.obs.rename(\n",
    "    columns={\n",
    "        \"n_genes_by_counts\": \"n_features_per_cell\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "atac.obs[\"log_total_counts\"] = np.log10(atac.obs[\"total_counts\"])\n",
    "atac.obs[\"idx_file\"] = [x.split(\"_\")[1] for x in atac.obs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../../rna_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_files = atac.obs[\"idx_file\"].unique()\n",
    "all_atac = []\n",
    "for file in idx_files:\n",
    "    print(file)\n",
    "    tmp = atac[atac.obs.idx_file == file].copy()\n",
    "    tmp.obs.index = [x.split(\"_\")[-1] for x in tmp.obs.index]\n",
    "    ac.tl.locate_fragments(\n",
    "        tmp,\n",
    "        f\"../../aurelie_data/revision_data/dna/sciHIPSD_merged/LFS_{file}/outs/fragments.tsv.gz\",\n",
    "    )\n",
    "    ac.tl.nucleosome_signal(tmp)\n",
    "    tss = ac.tl.tss_enrichment(tmp, n_tss=100000, random_state=666, features=features)\n",
    "\n",
    "    tmp.obs_names = f\"LFS_{file}_\" + tmp.obs_names\n",
    "\n",
    "    all_atac.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([ads.obs for ads in all_atac])\n",
    "merged\n",
    "merged.to_csv(\"../data/sciHIPSD_qc_parameters.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_scores = []\n",
    "nuc_signal = []\n",
    "for file in all_atac:\n",
    "    tss_scores.append(file.obs.tss_score.to_list())\n",
    "    nuc_signal.append(file.obs.nucleosome_signal.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_scores_flat = [item for sublist in tss_scores for item in sublist]\n",
    "nuc_signal_flat = [item for sublist in nuc_signal for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=tss_scores_flat)\n",
    "plt.xlim((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=nuc_signal_flat)\n",
    "plt.title(\"Distribution of the nucleosome signal\")\n",
    "plt.xlim(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"chr1:1-248956422\"\n",
    "hg_size = 3099706404\n",
    "sd = []\n",
    "lengths = []\n",
    "coverages = []\n",
    "for file in all_atac:\n",
    "    print(file)\n",
    "    file.obs.index = file.obs.index.str.split(\"_\").str[-1]\n",
    "    fragment_path = file.uns[\"files\"][\"fragments\"]\n",
    "    fragments = tools.fetch_regions_to_df(fragment_path=fragment_path, features=region)\n",
    "\n",
    "    fragments[\"length\"] = fragments.End - fragments.Start\n",
    "    fragments.set_index(keys=\"Cell\", inplace=True)\n",
    "    fragments = fragments.join(file.obs, how=\"right\")\n",
    "    f_length = fragments.length.median()\n",
    "    file.obs[\"coverage\"] = (file.obs[\"total_counts\"] * f_length) / hg_size\n",
    "    sd.append(file.obs)\n",
    "    lengths.append(fragments[\"length\"].to_list())\n",
    "    coverages.append(file.obs[\"coverage\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_flat = [item for sublist in lengths for item in sublist]\n",
    "coverages_flat = [item for sublist in coverages for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = [x for x in lengths_flat if x <= 1000]\n",
    "random_subset = random.sample(filtered_list, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=random_subset, bins=1000, density=True)\n",
    "plt.xlabel(\"Fragment length (bp)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlim((0, 1000))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=coverages_flat)\n",
    "plt.axvline(\n",
    "    np.nanmedian(coverages_flat),\n",
    "    label=f\"Median at {np.nanmedian(coverages_flat):.4f}\",\n",
    "    ls=\"--\",\n",
    "    c=\"grey\",\n",
    ")\n",
    "plt.title(\"Coverage\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CNVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cnv_files = glob.glob(\"../../sci/LFS*/hmmcopy_cells/*.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_cnv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnas = []\n",
    "\n",
    "for file in tqdm(all_cnv_files):\n",
    "    if file.endswith(\".bed\"):\n",
    "        cell = file.split(\"/\")[-1].split(\"_\")[2]\n",
    "        idx = \"_\".join(file.split(\"/\")[-3].split(\"-\")[:2])\n",
    "        new_cell = idx + \"_\" + cell\n",
    "        try:\n",
    "            cell_file = pd.read_csv(file, header=None, sep=\"\\t\")\n",
    "\n",
    "            cell_file[\"bin\"] = (\n",
    "                cell_file[0].astype(str)\n",
    "                + \":\"\n",
    "                + cell_file[1].astype(str)\n",
    "                + \"-\"\n",
    "                + cell_file[2].astype(str)\n",
    "            )\n",
    "            cell_file = cell_file.set_index(\"bin\")\n",
    "            cell_file = cell_file[[3]]\n",
    "            cell_file.columns = [new_cell]\n",
    "            cnas.append(cell_file)\n",
    "\n",
    "        except:\n",
    "            print(file)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna = pd.concat(cnas, ignore_index=False, axis=1)\n",
    "cna = cna - 1\n",
    "cna.replace(0, 1, inplace=True)\n",
    "cna = cna.T\n",
    "cna = cna[natsorted(cna.columns)]\n",
    "cna.to_csv(\"../data/CNVs_sciHIPSD_raw.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = pd.read_csv(\"../data/sciHIPSD_qc_parameters.csv.gz\", index_col=0)\n",
    "qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna = pd.read_csv(\"../data/CNVs_sciHIPSD_raw.csv.gz\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = qc[qc[\"n_features_per_cell\"] > (0.9 * 3102)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cna = cna.loc[cna.index.isin(filtered.index)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNVs filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = [col for col in cna.columns if not col.startswith(\"chrY\")]\n",
    "cna = cna[filtered_columns]\n",
    "cna = (cna - 2) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(cna)\n",
    "adata.obs = adata.obs.join(qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var[\"chromosome\"] = adata.var.index.str.split(\":\").str[0]\n",
    "adata.var[\"start\"] = (\n",
    "    adata.var.index.str.split(\":\").str[1].str.split(\"-\").str[0].astype(int)\n",
    ")\n",
    "adata.var[\"end\"] = (\n",
    "    adata.var.index.str.split(\":\").str[1].str.split(\"-\").str[1].astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.columns = [\"chromosome\", \"start\", \"end\"]\n",
    "adata.obsm[\"X_cnv\"] = adata.X\n",
    "adata.var[\"pos\"] = np.arange(adata.var.shape[0])\n",
    "chrom_dict = {}\n",
    "chrom_dict[\"chr_pos\"] = {}\n",
    "for tup in adata.var.itertuples():\n",
    "    if tup.chromosome not in chrom_dict[\"chr_pos\"]:\n",
    "        chrom_dict[\"chr_pos\"][tup.chromosome] = tup.pos\n",
    "    if chrom_dict[\"chr_pos\"][tup.chromosome] > tup.pos:\n",
    "        chrom_dict[\"chr_pos\"][tup.chromosome] = tup.pos\n",
    "adata.uns[\"cnv\"] = chrom_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata, n_pcs=10)\n",
    "sc.tl.leiden(adata, key_added=\"cnv_leiden\", resolution=0.15)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"cnv_leiden\"] = adata.obs[\"cnv_leiden\"].replace(\"0\", \"Cluster 1\")\n",
    "adata.obs[\"cnv_leiden\"] = adata.obs[\"cnv_leiden\"].replace(\"1\", \"Cluster 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"cnv_leiden\",\n",
    "    title=\"Leiden clusters\",\n",
    "    palette={\n",
    "        \"Cluster 1\": sns.palettes.color_palette(\"tab10\")[6],\n",
    "        \"Cluster 0\": sns.palettes.color_palette(\"tab10\")[0],\n",
    "    },\n",
    "    show=False,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sci_leiden_clusters.png\", dpi=300)\n",
    "plt.savefig(\"sci_leiden_clusters.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"cnv_leiden\",\n",
    "        \"n_features_per_cell\",\n",
    "        \"log_total_counts\",\n",
    "        \"tss_score\",\n",
    "    ],\n",
    "    title=[\n",
    "        \"Cluster\",\n",
    "        \"Number of non-empty bins per cell\",\n",
    "        \"log10(Total number of reads per cell)\",\n",
    "        \"TSS score enrichment per cell\",\n",
    "    ],\n",
    "    ncols=2,\n",
    "    vmax=\"p95\",\n",
    "    vmin=\"p05\",\n",
    "    show=False,\n",
    "    wspace=0.2,\n",
    "    palette={\n",
    "        \"Cluster 1\": sns.palettes.color_palette(\"tab10\")[6],\n",
    "        \"Cluster 0\": sns.palettes.color_palette(\"tab10\")[0],\n",
    "    },\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sci_leiden_clusters_qc.png\", dpi=300)\n",
    "plt.savefig(\"sci_leiden_clusters_qc.svg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(\"../data/sci_leiden_clusters.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
